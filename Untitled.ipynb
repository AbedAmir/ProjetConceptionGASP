{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- kit_id: integer (nullable = true)\n",
      " |-- participant_id: integer (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- lon: double (nullable = true)\n",
      " |-- PM2-5: string (nullable = true)\n",
      " |-- PM10: string (nullable = true)\n",
      " |-- PM1-0: string (nullable = true)\n",
      " |-- NO2: string (nullable = true)\n",
      " |-- BC: string (nullable = true)\n",
      " |-- activity: string (nullable = true)\n",
      " |-- event: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql.functions import col, when, unix_timestamp\n",
    "sc = SparkContext.getOrCreate()\n",
    "df = spark.read.option(\"header\",True).option(\"inferSchema\",True).csv(\"C:/Users/Winsido/Desktop/VGP-week3-data.csv\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\n",
    "    (\"PM2-5\"),\n",
    "    when(\n",
    "        col(\"PM2-5\") == \"NULL\",\n",
    "        None\n",
    "    ).otherwise(col(\"PM2-5\"))\n",
    ")\n",
    "df = df.withColumn(\n",
    "    (\"PM10\"),\n",
    "    when(\n",
    "        col(\"PM10\") == \"NULL\",\n",
    "        None\n",
    "    ).otherwise(col(\"PM10\"))\n",
    ")\n",
    "df = df.withColumn(\n",
    "    (\"PM1-0\"),\n",
    "    when(\n",
    "        col(\"PM1-0\") == \"NULL\",\n",
    "        None\n",
    "    ).otherwise(col(\"PM1-0\"))\n",
    ")\n",
    "df = df.withColumn(\n",
    "    (\"NO2\"),\n",
    "    when(\n",
    "        col(\"NO2\") == \"NULL\",\n",
    "        None\n",
    "    ).otherwise(col(\"NO2\"))\n",
    ")\n",
    "df = df.withColumn(\n",
    "    (\"activity\"),\n",
    "    when(\n",
    "        col(\"activity\") == \"NULL\",\n",
    "        None\n",
    "    ).otherwise(col(\"activity\"))\n",
    ")\n",
    "df = df.withColumn(\n",
    "    (\"event\"),\n",
    "    when(\n",
    "        col(\"event\") == \"NULL\",\n",
    "        None\n",
    "    ).otherwise(col(\"event\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+-------------------+----------------+----------------+-----+----+-----+----+----+--------+-----+\n",
      "|kit_id|participant_id|               time|             lat|             lon|PM2-5|PM10|PM1-0| NO2|  BC|activity|event|\n",
      "+------+--------------+-------------------+----------------+----------------+-----+----+-----+----+----+--------+-----+\n",
      "|    80|       9999964|2019-11-14 09:00:00|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:00:10|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:00:20|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:00:30|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:00:40|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:00:50|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:01:00|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:01:10|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:01:20|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:01:30|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:01:40|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:01:50|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:02:00|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:02:10|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:02:20|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:02:30|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:02:40|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:02:50|48.7717466666667|2.00590833333333| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:03:00|48.7717466666667|2.00590833333333| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:03:10|       48.771765|2.00590333333333| null|null| null|null|NULL|    null| null|\n",
      "+------+--------------+-------------------+----------------+----------------+-----+----+-----+----+----+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+-------------------+----------------+----------------+-----+----+-----+---+---+--------+-------------------+\n",
      "|kit_id|participant_id|               time|             lat|             lon|PM2-5|PM10|PM1-0|NO2| BC|activity|              event|\n",
      "+------+--------------+-------------------+----------------+----------------+-----+----+-----+---+---+--------+-------------------+\n",
      "|    80|       9999964|2019-11-15 09:00:00|48.7717183333333|2.00601666666667| null|null| null|  7|369|  Bureau|Arrêter De Cuisiner|\n",
      "|    80|       9999964|2019-11-15 09:00:10|48.7717183333333|2.00601666666667| null|null| null|  7|369|  Bureau|Arrêter De Cuisiner|\n",
      "|    80|       9999964|2019-11-15 09:00:20|48.7717183333333|2.00601666666667| null|null| null|  7|369|  Bureau|Arrêter De Cuisiner|\n",
      "|    80|       9999964|2019-11-15 09:00:30|48.7717216666667|2.00587833333333| null|null| null|  7|369|  Bureau|Arrêter De Cuisiner|\n",
      "|    80|       9999964|2019-11-15 09:00:40|48.7717266666667|2.00586333333333| null|null| null|  7|369|  Bureau|Arrêter De Cuisiner|\n",
      "|    80|       9999964|2019-11-15 09:00:50|48.7717266666667|2.00586333333333| null|null| null|  7|369|  Bureau|Arrêter De Cuisiner|\n",
      "|    80|       9999964|2019-11-15 09:01:00|48.7717266666667|2.00586333333333| null|null| null|  6|396|  Bureau|Arrêter De Cuisiner|\n",
      "|    80|       9999964|2019-11-15 09:01:10|48.7717266666667|2.00586333333333| null|null| null|  6|396|  Bureau|Arrêter De Cuisiner|\n",
      "|    80|       9999964|2019-11-15 09:01:20|48.7717266666667|2.00586333333333| null|null| null|  6|396|  Bureau|Arrêter De Cuisiner|\n",
      "|    80|       9999964|2019-11-15 09:01:30|48.7717266666667|2.00586333333333| null|null| null|  6|396|  Bureau|Arrêter De Cuisiner|\n",
      "|    80|       9999964|2019-11-15 09:01:40|48.7717266666667|2.00586333333333| null|null| null|  6|396|  Bureau|Arrêter De Cuisiner|\n",
      "|    80|       9999964|2019-11-15 09:01:50|48.7717266666667|2.00586333333333| null|null| null|  6|396|  Bureau|Arrêter De Cuisiner|\n",
      "|    80|       9999964|2019-11-15 09:02:00|48.7717266666667|2.00586333333333| null|null| null|  6|382|  Bureau|Arrêter De Cuisiner|\n",
      "|    80|       9999964|2019-11-15 09:02:10|48.7717266666667|2.00586333333333| null|null| null|  6|382|  Bureau|Arrêter De Cuisiner|\n",
      "|    80|       9999964|2019-11-15 09:02:20|48.7717266666667|2.00586333333333| null|null| null|  6|382|  Bureau|Arrêter De Cuisiner|\n",
      "|    80|       9999964|2019-11-15 09:02:30|48.7717266666667|2.00586333333333| null|null| null|  6|382|  Bureau|Arrêter De Cuisiner|\n",
      "|    80|       9999964|2019-11-15 09:02:40|48.7717266666667|2.00586333333333| null|null| null|  6|382|  Bureau|Arrêter De Cuisiner|\n",
      "|    80|       9999964|2019-11-15 09:02:50|48.7717266666667|2.00586333333333| null|null| null|  6|382|  Bureau|Arrêter De Cuisiner|\n",
      "|    80|       9999964|2019-11-15 09:03:00|48.7717266666667|2.00586333333333|    3|   4|    4|  7|376|  Bureau|Arrêter De Cuisiner|\n",
      "|    80|       9999964|2019-11-15 09:03:10|48.7717266666667|2.00586333333333|    3|   4|    4|  7|376|  Bureau|Arrêter De Cuisiner|\n",
      "+------+--------------+-------------------+----------------+----------------+-----+----+-----+---+---+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(col(\"activity\").isNotNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+-------------------+----------------+--------+-----+----+-----+----+----+--------+-----+\n",
      "|kit_id|participant_id|               time|             lat|     lon|PM2-5|PM10|PM1-0| NO2|  BC|activity|event|\n",
      "+------+--------------+-------------------+----------------+--------+-----+----+-----+----+----+--------+-----+\n",
      "|    80|       9999964|2019-11-14 09:00:00|48.7717766666667|2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:00:10|48.7717766666667|2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:00:20|48.7717766666667|2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:00:30|48.7717766666667|2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:00:40|48.7717766666667|2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:00:50|48.7717766666667|2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:01:00|48.7717766666667|2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:01:10|48.7717766666667|2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:01:20|48.7717766666667|2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:01:30|48.7717766666667|2.006005| null|null| null|null|NULL|    null| null|\n",
      "+------+--------------+-------------------+----------------+--------+-----+----+-----+----+----+--------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.sort(\"time\")\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- kit_id: integer (nullable = true)\n",
      " |-- participant_id: integer (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- lon: double (nullable = true)\n",
      " |-- PM2-5: string (nullable = true)\n",
      " |-- PM10: string (nullable = true)\n",
      " |-- PM1-0: string (nullable = true)\n",
      " |-- NO2: string (nullable = true)\n",
      " |-- BC: string (nullable = true)\n",
      " |-- activity: string (nullable = true)\n",
      " |-- event: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- kit_id: integer (nullable = true)\n",
      " |-- participant_id: integer (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- lon: double (nullable = true)\n",
      " |-- PM2-5: double (nullable = true)\n",
      " |-- PM10: string (nullable = true)\n",
      " |-- PM1-0: string (nullable = true)\n",
      " |-- NO2: string (nullable = true)\n",
      " |-- BC: string (nullable = true)\n",
      " |-- activity: string (nullable = true)\n",
      " |-- event: string (nullable = true)\n",
      "\n",
      "+------+--------------+-------------------+----------------+----------------+-----+----+-----+---+----+----------+-----+\n",
      "|kit_id|participant_id|               time|             lat|             lon|PM2-5|PM10|PM1-0|NO2|  BC|  activity|event|\n",
      "+------+--------------+-------------------+----------------+----------------+-----+----+-----+---+----+----------+-----+\n",
      "|    88|       9999920|2019-11-15 12:16:00|48.8066483333333|         2.15792| 73.0|  76|   76|  0|NULL|  Domicile|Fumer|\n",
      "|    88|       9999920|2019-11-15 12:16:50|48.8066466666667|         2.15809| 73.0|  76|   76|  0|NULL|  Domicile|Fumer|\n",
      "|    88|       9999920|2019-11-15 12:17:00|        48.80666|        2.158165| 68.0|  73|   73|  3|NULL|  Domicile|Fumer|\n",
      "|    88|       9999920|2019-11-15 12:17:10|48.8066683333333|2.15812833333333| 68.0|  73|   73|  3|NULL|  Domicile|Fumer|\n",
      "|    88|       9999920|2019-11-15 12:17:20|48.8066133333333|2.15816666666667| 68.0|  73|   73|  3|NULL|  Domicile|Fumer|\n",
      "|    88|       9999920|2019-11-15 12:17:30|48.8066683333333|2.15825166666667| 68.0|  73|   73|  3|NULL|  Domicile|Fumer|\n",
      "|    88|       9999920|2019-11-15 12:17:40|48.8066966666667|          2.1583| 68.0|  73|   73|  3|NULL|  Domicile|Fumer|\n",
      "|    88|       9999920|2019-11-21 12:52:00|48.8548066666667|2.36272333333333| 61.0|  63|   63| 23|NULL|Restaurant| null|\n",
      "|    88|       9999920|2019-11-21 12:52:10|       48.854875|2.36253833333333| 61.0|  63|   63| 23|NULL|Restaurant| null|\n",
      "|    88|       9999920|2019-11-21 12:52:20|48.8548983333333|2.36262833333333| 61.0|  63|   63| 23|NULL|Restaurant| null|\n",
      "|    88|       9999920|2019-11-21 12:52:30|48.8545483333333|        2.362685| 61.0|  63|   63| 23|NULL|Restaurant| null|\n",
      "|    88|       9999920|2019-11-21 12:54:20|       48.854415|2.36252833333333| 94.0|  98|   98| 24|NULL|Restaurant| null|\n",
      "|    88|       9999920|2019-11-21 12:54:30|48.8544766666667|          2.3625| 94.0|  98|   98| 24|NULL|Restaurant| null|\n",
      "|    88|       9999920|2019-11-21 12:54:40|        48.85458|2.36239166666667| 94.0|  98|   98| 24|NULL|Restaurant| null|\n",
      "|    88|       9999920|2019-11-21 12:54:50|        48.85464|2.36250666666667| 94.0|  98|   98| 24|NULL|Restaurant| null|\n",
      "+------+--------------+-------------------+----------------+----------------+-----+----+-----+---+----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Pas trop bon\n",
    "from pyspark.sql.types import DoubleType, DateType,TimestampType\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "df = df.withColumn(\"PM2-5\",df[\"PM2-5\"].cast(DoubleType()))\n",
    "#df = df.withColumn(\"time\",df[\"time\"].cast(DateType()))\n",
    "df.printSchema()\n",
    "df.filter(df[\"PM2-5\"] > 60).show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+-------------------+----------------+----------------+-----+----+-----+----+----+--------+-----+\n",
      "|kit_id|participant_id|               time|             lat|             lon|PM2-5|PM10|PM1-0| NO2|  BC|activity|event|\n",
      "+------+--------------+-------------------+----------------+----------------+-----+----+-----+----+----+--------+-----+\n",
      "|    80|       9999964|2019-11-14 09:00:00|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:00:10|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:00:20|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:00:30|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:00:40|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:00:50|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:01:00|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:01:10|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:01:20|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:01:30|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:01:40|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:01:50|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:02:00|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:02:10|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:02:20|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:02:30|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:02:40|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:02:50|48.7717466666667|2.00590833333333| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:03:00|48.7717466666667|2.00590833333333| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:03:10|       48.771765|2.00590333333333| null|null| null|null|NULL|    null| null|\n",
      "+------+--------------+-------------------+----------------+----------------+-----+----+-----+----+----+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'printSchema'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-09aa658342f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprintSchema\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'printSchema'"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "cannot resolve 'unix_timestamp(`time`, 'yyyy-MM-dd HH:mm:ss')' due to data type mismatch: argument 1 requires (string or date or timestamp) type, however, '`time`' is of bigint type.;;\n'Project [kit_id#961, participant_id#962, unix_timestamp(time#1736L, yyyy-MM-dd HH:mm:ss, Some(Europe/Paris)) AS time#1752, lat#964, lon#965, PM2-5#985, PM10#998, PM1-0#1011, NO2#1024, BC#970, activity#1037, event#1050]\n+- Project [kit_id#961, participant_id#962, unix_timestamp(time#963, yyyy-MM-dd HH:mm:ss, Some(Europe/Paris)) AS time#1736L, lat#964, lon#965, PM2-5#985, PM10#998, PM1-0#1011, NO2#1024, BC#970, activity#1037, event#1050]\n   +- Project [kit_id#961, participant_id#962, time#963, lat#964, lon#965, PM2-5#985, PM10#998, PM1-0#1011, NO2#1024, BC#970, activity#1037, CASE WHEN (event#972 = NULL) THEN cast(null as string) ELSE event#972 END AS event#1050]\n      +- Project [kit_id#961, participant_id#962, time#963, lat#964, lon#965, PM2-5#985, PM10#998, PM1-0#1011, NO2#1024, BC#970, CASE WHEN (activity#971 = NULL) THEN cast(null as string) ELSE activity#971 END AS activity#1037, event#972]\n         +- Project [kit_id#961, participant_id#962, time#963, lat#964, lon#965, PM2-5#985, PM10#998, PM1-0#1011, CASE WHEN (NO2#969 = NULL) THEN cast(null as string) ELSE NO2#969 END AS NO2#1024, BC#970, activity#971, event#972]\n            +- Project [kit_id#961, participant_id#962, time#963, lat#964, lon#965, PM2-5#985, PM10#998, CASE WHEN (PM1-0#968 = NULL) THEN cast(null as string) ELSE PM1-0#968 END AS PM1-0#1011, NO2#969, BC#970, activity#971, event#972]\n               +- Project [kit_id#961, participant_id#962, time#963, lat#964, lon#965, PM2-5#985, CASE WHEN (PM10#967 = NULL) THEN cast(null as string) ELSE PM10#967 END AS PM10#998, PM1-0#968, NO2#969, BC#970, activity#971, event#972]\n                  +- Project [kit_id#961, participant_id#962, time#963, lat#964, lon#965, CASE WHEN (PM2-5#966 = NULL) THEN cast(null as string) ELSE PM2-5#966 END AS PM2-5#985, PM10#967, PM1-0#968, NO2#969, BC#970, activity#971, event#972]\n                     +- RelationV2[kit_id#961, participant_id#962, time#963, lat#964, lon#965, PM2-5#966, PM10#967, PM1-0#968, NO2#969, BC#970, activity#971, event#972] csv file:/C:/Users/Winsido/Desktop/VGP-week3-data.csv\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mC:\\Spark\\spark\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\spark\\python\\lib\\py4j-0.10.8.1-src.zip\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    329\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o243.withColumn.\n: org.apache.spark.sql.AnalysisException: cannot resolve 'unix_timestamp(`time`, 'yyyy-MM-dd HH:mm:ss')' due to data type mismatch: argument 1 requires (string or date or timestamp) type, however, '`time`' is of bigint type.;;\n'Project [kit_id#961, participant_id#962, unix_timestamp(time#1736L, yyyy-MM-dd HH:mm:ss, Some(Europe/Paris)) AS time#1752, lat#964, lon#965, PM2-5#985, PM10#998, PM1-0#1011, NO2#1024, BC#970, activity#1037, event#1050]\n+- Project [kit_id#961, participant_id#962, unix_timestamp(time#963, yyyy-MM-dd HH:mm:ss, Some(Europe/Paris)) AS time#1736L, lat#964, lon#965, PM2-5#985, PM10#998, PM1-0#1011, NO2#1024, BC#970, activity#1037, event#1050]\n   +- Project [kit_id#961, participant_id#962, time#963, lat#964, lon#965, PM2-5#985, PM10#998, PM1-0#1011, NO2#1024, BC#970, activity#1037, CASE WHEN (event#972 = NULL) THEN cast(null as string) ELSE event#972 END AS event#1050]\n      +- Project [kit_id#961, participant_id#962, time#963, lat#964, lon#965, PM2-5#985, PM10#998, PM1-0#1011, NO2#1024, BC#970, CASE WHEN (activity#971 = NULL) THEN cast(null as string) ELSE activity#971 END AS activity#1037, event#972]\n         +- Project [kit_id#961, participant_id#962, time#963, lat#964, lon#965, PM2-5#985, PM10#998, PM1-0#1011, CASE WHEN (NO2#969 = NULL) THEN cast(null as string) ELSE NO2#969 END AS NO2#1024, BC#970, activity#971, event#972]\n            +- Project [kit_id#961, participant_id#962, time#963, lat#964, lon#965, PM2-5#985, PM10#998, CASE WHEN (PM1-0#968 = NULL) THEN cast(null as string) ELSE PM1-0#968 END AS PM1-0#1011, NO2#969, BC#970, activity#971, event#972]\n               +- Project [kit_id#961, participant_id#962, time#963, lat#964, lon#965, PM2-5#985, CASE WHEN (PM10#967 = NULL) THEN cast(null as string) ELSE PM10#967 END AS PM10#998, PM1-0#968, NO2#969, BC#970, activity#971, event#972]\n                  +- Project [kit_id#961, participant_id#962, time#963, lat#964, lon#965, CASE WHEN (PM2-5#966 = NULL) THEN cast(null as string) ELSE PM2-5#966 END AS PM2-5#985, PM10#967, PM1-0#968, NO2#969, BC#970, activity#971, event#972]\n                     +- RelationV2[kit_id#961, participant_id#962, time#963, lat#964, lon#965, PM2-5#966, PM10#967, PM1-0#968, NO2#969, BC#970, activity#971, event#972] csv file:/C:/Users/Winsido/Desktop/VGP-week3-data.csv\n\r\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\r\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$$nestedInanonfun$checkAnalysis$1$2.applyOrElse(CheckAnalysis.scala:131)\r\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$$nestedInanonfun$checkAnalysis$1$2.applyOrElse(CheckAnalysis.scala:122)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformUp$2(TreeNode.scala:310)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:72)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:310)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformUp$1(TreeNode.scala:307)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$mapChildren$1(TreeNode.scala:376)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:214)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:374)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:327)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:307)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$transformExpressionsUp$1(QueryPlan.scala:97)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$1(QueryPlan.scala:109)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:72)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:109)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.recursiveTransform$1(QueryPlan.scala:120)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$3(QueryPlan.scala:125)\r\n\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\r\n\tat scala.collection.immutable.List.foreach(List.scala:392)\r\n\tat scala.collection.TraversableLike.map(TraversableLike.scala:238)\r\n\tat scala.collection.TraversableLike.map$(TraversableLike.scala:231)\r\n\tat scala.collection.immutable.List.map(List.scala:298)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.recursiveTransform$1(QueryPlan.scala:125)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$4(QueryPlan.scala:130)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:214)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:130)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:97)\r\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1(CheckAnalysis.scala:122)\r\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1$adapted(CheckAnalysis.scala:90)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:154)\r\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:90)\r\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:87)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:122)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:148)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:145)\r\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:66)\r\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)\r\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:63)\r\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:63)\r\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:55)\r\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:87)\r\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withPlan(Dataset.scala:3436)\r\n\tat org.apache.spark.sql.Dataset.select(Dataset.scala:1413)\r\n\tat org.apache.spark.sql.Dataset.withColumns(Dataset.scala:2224)\r\n\tat org.apache.spark.sql.Dataset.withColumn(Dataset.scala:2191)\r\n\tat sun.reflect.GeneratedMethodAccessor70.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-1f3a151dc129>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0munix_timestamp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'yyyy-MM-dd HH:mm:ss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malias\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\spark\\python\\pyspark\\sql\\dataframe.py\u001b[0m in \u001b[0;36mwithColumn\u001b[1;34m(self, colName, col)\u001b[0m\n\u001b[0;32m   1991\u001b[0m         \"\"\"\n\u001b[0;32m   1992\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"col should be Column\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1993\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1994\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1995\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mignore_unicode_prefix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\spark\\python\\lib\\py4j-0.10.8.1-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1284\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1285\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1286\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1288\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\spark\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    100\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUnknownException\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mconverted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: cannot resolve 'unix_timestamp(`time`, 'yyyy-MM-dd HH:mm:ss')' due to data type mismatch: argument 1 requires (string or date or timestamp) type, however, '`time`' is of bigint type.;;\n'Project [kit_id#961, participant_id#962, unix_timestamp(time#1736L, yyyy-MM-dd HH:mm:ss, Some(Europe/Paris)) AS time#1752, lat#964, lon#965, PM2-5#985, PM10#998, PM1-0#1011, NO2#1024, BC#970, activity#1037, event#1050]\n+- Project [kit_id#961, participant_id#962, unix_timestamp(time#963, yyyy-MM-dd HH:mm:ss, Some(Europe/Paris)) AS time#1736L, lat#964, lon#965, PM2-5#985, PM10#998, PM1-0#1011, NO2#1024, BC#970, activity#1037, event#1050]\n   +- Project [kit_id#961, participant_id#962, time#963, lat#964, lon#965, PM2-5#985, PM10#998, PM1-0#1011, NO2#1024, BC#970, activity#1037, CASE WHEN (event#972 = NULL) THEN cast(null as string) ELSE event#972 END AS event#1050]\n      +- Project [kit_id#961, participant_id#962, time#963, lat#964, lon#965, PM2-5#985, PM10#998, PM1-0#1011, NO2#1024, BC#970, CASE WHEN (activity#971 = NULL) THEN cast(null as string) ELSE activity#971 END AS activity#1037, event#972]\n         +- Project [kit_id#961, participant_id#962, time#963, lat#964, lon#965, PM2-5#985, PM10#998, PM1-0#1011, CASE WHEN (NO2#969 = NULL) THEN cast(null as string) ELSE NO2#969 END AS NO2#1024, BC#970, activity#971, event#972]\n            +- Project [kit_id#961, participant_id#962, time#963, lat#964, lon#965, PM2-5#985, PM10#998, CASE WHEN (PM1-0#968 = NULL) THEN cast(null as string) ELSE PM1-0#968 END AS PM1-0#1011, NO2#969, BC#970, activity#971, event#972]\n               +- Project [kit_id#961, participant_id#962, time#963, lat#964, lon#965, PM2-5#985, CASE WHEN (PM10#967 = NULL) THEN cast(null as string) ELSE PM10#967 END AS PM10#998, PM1-0#968, NO2#969, BC#970, activity#971, event#972]\n                  +- Project [kit_id#961, participant_id#962, time#963, lat#964, lon#965, CASE WHEN (PM2-5#966 = NULL) THEN cast(null as string) ELSE PM2-5#966 END AS PM2-5#985, PM10#967, PM1-0#968, NO2#969, BC#970, activity#971, event#972]\n                     +- RelationV2[kit_id#961, participant_id#962, time#963, lat#964, lon#965, PM2-5#966, PM10#967, PM1-0#968, NO2#969, BC#970, activity#971, event#972] csv file:/C:/Users/Winsido/Desktop/VGP-week3-data.csv\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('time',unix_timestamp('time', 'yyyy-MM-dd HH:mm:ss').alias('time'))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+-------------------+----------------+----------------+-----+----+-----+----+----+--------+-----+\n",
      "|kit_id|participant_id|               time|             lat|             lon|PM2-5|PM10|PM1-0| NO2|  BC|activity|event|\n",
      "+------+--------------+-------------------+----------------+----------------+-----+----+-----+----+----+--------+-----+\n",
      "|    80|       9999964|2019-11-14 09:00:00|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:00:10|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:00:20|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:00:30|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:00:40|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:00:50|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:01:00|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:01:10|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:01:20|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:01:30|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:01:40|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:01:50|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:02:00|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:02:10|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:02:20|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:02:30|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:02:40|48.7717766666667|        2.006005| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:02:50|48.7717466666667|2.00590833333333| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:03:00|48.7717466666667|2.00590833333333| null|null| null|null|NULL|    null| null|\n",
      "|    80|       9999964|2019-11-14 09:03:10|       48.771765|2.00590333333333| null|null| null|null|NULL|    null| null|\n",
      "+------+--------------+-------------------+----------------+----------------+-----+----+-----+----+----+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pandas_df = df.toPandas()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
